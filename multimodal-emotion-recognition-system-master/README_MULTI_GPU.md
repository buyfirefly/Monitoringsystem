# å¤šGPUè®­ç»ƒæŒ‡å— - 3x RTX 4090ä¼˜åŒ–

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•ä½¿ç”¨3ä¸ªRTX 4090 GPUè¿›è¡Œå¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«æ¨¡å‹çš„è®­ç»ƒã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ä½¿ç”¨ä¼˜åŒ–çš„è®­ç»ƒè„šæœ¬

```bash
# ä½¿ç”¨é»˜è®¤ä¼˜åŒ–å‚æ•°
python train_multi_gpu.py --data_dir /path/to/your/dataset

# è‡ªå®šä¹‰å‚æ•°
python train_multi_gpu.py \
    --data_dir /path/to/your/dataset \
    --dataset MELD \
    --batch_size 20 \
    --epochs 150
```

### 2. ä½¿ç”¨åŸå§‹è®­ç»ƒè„šæœ¬

```bash
python multimodal_emotion/train.py \
    --data_dir /path/to/your/dataset \
    --use_multi_gpu \
    --gpu_ids 0 1 2 \
    --batch_size 16 \
    --num_workers 12 \
    --auto_scale_lr
```

## âš™ï¸ ä¼˜åŒ–é…ç½®

### GPUé…ç½®
- **GPUæ•°é‡**: 3ä¸ª RTX 4090 (24GB each)
- **æ€»æ˜¾å­˜**: 72GB
- **å¹¶è¡Œç­–ç•¥**: DataParallel

### æ‰¹æ¬¡å¤§å°ä¼˜åŒ–
- **æ¨èé…ç½®**: æ¯GPU 20-24ä¸ªæ ·æœ¬
- **æ€»æ‰¹æ¬¡å¤§å°**: 60-72ä¸ªæ ·æœ¬
- **å†…å­˜ä½¿ç”¨**: çº¦18-20GB per GPU

### å­¦ä¹ ç‡è°ƒæ•´
- **è‡ªåŠ¨ç¼©æ”¾**: å­¦ä¹ ç‡ Ã— GPUæ•°é‡
- **Visual Encoder**: 3e-4
- **Audio Encoder**: 3e-4  
- **Fusion Layer**: 3e-3

### æ•°æ®åŠ è½½ä¼˜åŒ–
- **Workers**: 12ä¸ª (4 per GPU)
- **Pin Memory**: å¯ç”¨
- **Non-blocking Transfer**: å¯ç”¨

## ğŸ“Š æ€§èƒ½ç›‘æ§

### TensorBoardç›‘æ§
```bash
tensorboard --logdir ./logs_multi_gpu
```

ç›‘æ§æŒ‡æ ‡:
- è®­ç»ƒ/éªŒè¯æŸå¤±å’Œå‡†ç¡®ç‡
- æ¯ä¸ªGPUçš„å†…å­˜ä½¿ç”¨æƒ…å†µ
- å­¦ä¹ ç‡å˜åŒ–
- æ¢¯åº¦èŒƒæ•°

### GPUå†…å­˜ç›‘æ§
```bash
# å®æ—¶ç›‘æ§GPUä½¿ç”¨æƒ…å†µ
watch -n 1 nvidia-smi

# æˆ–ä½¿ç”¨gpustat
pip install gpustat
gpustat -i 1
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. å†…å­˜ä¸è¶³ (OOM)
```bash
# å‡å°æ‰¹æ¬¡å¤§å°
python train_multi_gpu.py --data_dir /path/to/dataset --batch_size 16

# æˆ–å‡å°‘workers
python train_multi_gpu.py --data_dir /path/to/dataset --num_workers 8
```

#### 2. GPUåˆ©ç”¨ç‡ä½
- æ£€æŸ¥æ•°æ®åŠ è½½æ˜¯å¦æˆä¸ºç“¶é¢ˆ
- å¢åŠ `num_workers`
- ç¡®ä¿`pin_memory=True`

#### 3. è®­ç»ƒé€Ÿåº¦æ…¢
```bash
# å¯ç”¨cuDNN benchmark
export TORCH_CUDNN_V8_API_ENABLED=1

# ä¼˜åŒ–å†…å­˜åˆ†é…
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128
```

#### 4. æ•°æ®åŠ è½½é”™è¯¯
ç¡®ä¿å·²åº”ç”¨é”™è¯¯å¤„ç†ä¿®å¤:
- `data_utils.py`ä¸­çš„è§†é¢‘è¯»å–é”™è¯¯å¤„ç†
- `fusion_model.py`ä¸­çš„ResNet18æƒé‡è­¦å‘Šä¿®å¤

## ğŸ“ˆ æ€§èƒ½åŸºå‡†

### é¢„æœŸæ€§èƒ½ (3x RTX 4090)
- **è®­ç»ƒé€Ÿåº¦**: ~2-3ç§’/epoch (MELDæ•°æ®é›†)
- **å†…å­˜ä½¿ç”¨**: 18-20GB per GPU
- **GPUåˆ©ç”¨ç‡**: 85-95%
- **æ•°æ®åŠ è½½**: <5% ç­‰å¾…æ—¶é—´

### ä¸å•GPUå¯¹æ¯”
- **é€Ÿåº¦æå‡**: 2.7-2.9x
- **å†…å­˜æ•ˆç‡**: æ›´å¥½çš„æ‰¹æ¬¡å¤§å°
- **è®­ç»ƒç¨³å®šæ€§**: æ›´å¤§çš„æœ‰æ•ˆæ‰¹æ¬¡å¤§å°

## ğŸ¯ æœ€ä½³å®è·µ

### 1. æ‰¹æ¬¡å¤§å°é€‰æ‹©
```python
# æ ¹æ®æ¨¡å‹å¤æ‚åº¦è°ƒæ•´
# ç®€å•æ¨¡å‹: 24-28 per GPU
# å¤æ‚æ¨¡å‹: 16-20 per GPU
# è¶…å¤§æ¨¡å‹: 8-12 per GPU
```

### 2. å­¦ä¹ ç‡è°ƒåº¦
```python
# æ¨èä½¿ç”¨ä½™å¼¦é€€ç«
--scheduler cosine

# æˆ–ä½¿ç”¨ReduceLROnPlateau
--scheduler plateau --patience 10 --factor 0.5
```

### 3. æ¢¯åº¦ç´¯ç§¯ (å¯é€‰)
å¦‚æœéœ€è¦æ›´å¤§çš„æœ‰æ•ˆæ‰¹æ¬¡å¤§å°:
```python
# åœ¨train.pyä¸­æ·»åŠ æ¢¯åº¦ç´¯ç§¯
accumulation_steps = 2  # æœ‰æ•ˆæ‰¹æ¬¡å¤§å° = batch_size * num_gpus * accumulation_steps
```

### 4. æ··åˆç²¾åº¦è®­ç»ƒ (å¯é€‰)
```python
# ä½¿ç”¨AMPåŠ é€Ÿè®­ç»ƒ
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()
with autocast():
    outputs = model(images, mel_specs)
    loss = criterion(outputs, labels)

scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

## ğŸ“ é…ç½®æ–‡ä»¶ç¤ºä¾‹

### config_3x4090.json
```json
{
    "use_multi_gpu": true,
    "gpu_ids": [0, 1, 2],
    "batch_size": 22,
    "num_workers": 12,
    "lr_visual": 3e-4,
    "lr_audio": 3e-4,
    "lr_fusion": 3e-3,
    "auto_scale_lr": false,
    "fusion_type": "attention",
    "scheduler": "cosine",
    "grad_clip": 1.0,
    "epochs": 100
}
```

## ğŸ” è°ƒè¯•æŠ€å·§

### 1. éªŒè¯å¤šGPUè®¾ç½®
```python
import torch
print(f"å¯ç”¨GPU: {torch.cuda.device_count()}")
print(f"å½“å‰GPU: {torch.cuda.current_device()}")
for i in range(torch.cuda.device_count()):
    print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
```

### 2. æ£€æŸ¥æ¨¡å‹å¹¶è¡Œ
```python
# åœ¨è®­ç»ƒè„šæœ¬ä¸­æ·»åŠ 
if hasattr(model, 'module'):
    print("æ¨¡å‹å·²ä½¿ç”¨DataParallelåŒ…è£…")
else:
    print("æ¨¡å‹æœªä½¿ç”¨å¹¶è¡Œ")
```

### 3. ç›‘æ§æ•°æ®æµ
```python
# æ·»åŠ åˆ°è®­ç»ƒå¾ªç¯
print(f"Batch shape: images={images.shape}, audio={mel_specs.shape}")
print(f"Device: {images.device}")
```

## ğŸ“ æ”¯æŒ

å¦‚æœé‡åˆ°é—®é¢˜:
1. æ£€æŸ¥GPUé©±åŠ¨å’ŒCUDAç‰ˆæœ¬å…¼å®¹æ€§
2. ç¡®è®¤PyTorchç‰ˆæœ¬æ”¯æŒä½ çš„CUDAç‰ˆæœ¬
3. éªŒè¯æ•°æ®é›†è·¯å¾„å’Œæ ¼å¼
4. æŸ¥çœ‹é”™è¯¯æ—¥å¿—å’ŒGPUå†…å­˜ä½¿ç”¨æƒ…å†µ

---

**æ³¨æ„**: æœ¬é…ç½®ä¸“ä¸º3x RTX 4090ä¼˜åŒ–ï¼Œå…¶ä»–GPUé…ç½®å¯èƒ½éœ€è¦è°ƒæ•´å‚æ•°ã€‚