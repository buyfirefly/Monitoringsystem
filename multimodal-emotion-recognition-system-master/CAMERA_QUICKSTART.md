# æ‘„åƒå¤´æƒ…ç»ªç›‘æµ‹å¿«é€Ÿå¼€å§‹æŒ‡å—

æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨å¿«é€Ÿä¸Šæ‰‹å®æ—¶æ‘„åƒå¤´æƒ…ç»ªç›‘æµ‹åŠŸèƒ½ã€‚

## ğŸš€ å¿«é€Ÿä½“éªŒ

### å¤šæ¨¡æ€æƒ…ç»ªç›‘æµ‹ï¼ˆéœ€è¦è®­ç»ƒæ¨¡å‹ï¼‰

**é€‚åˆåœºæ™¯ï¼š** é«˜ç²¾åº¦åº”ç”¨ã€ç ”ç©¶å¼€å‘ã€ç”Ÿäº§ç¯å¢ƒ

```bash
# 1. å®‰è£…å®Œæ•´ä¾èµ–
pip install -r requirements_camera.txt

# 2. ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚æœæœ‰ï¼‰
python realtime_camera_emotion.py --model_path ./checkpoints/best_model.pth

# 3. æˆ–ä½¿ç”¨å¯¼å‡ºçš„ONNXæ¨¡å‹
python realtime_camera_emotion.py --model_path ./exported_models/model.onnx
```

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

## ğŸ”§ ç¯å¢ƒé…ç½®

### macOS
```bash
# å®‰è£…ç³»ç»Ÿä¾èµ–
brew install portaudio ffmpeg

# å®‰è£…Pythonä¾èµ–
pip install -r requirements_camera.txt

# æˆæƒæ‘„åƒå¤´å’Œéº¦å…‹é£æƒé™
# ç³»ç»Ÿåå¥½è®¾ç½® -> å®‰å…¨æ€§ä¸éšç§ -> éšç§ -> æ‘„åƒå¤´/éº¦å…‹é£
```

### Ubuntu/Debian
```bash
# å®‰è£…ç³»ç»Ÿä¾èµ–
sudo apt-get update
sudo apt-get install portaudio19-dev python3-pyaudio ffmpeg

# å®‰è£…Pythonä¾èµ–
pip install -r requirements_camera.txt

# æ·»åŠ ç”¨æˆ·åˆ°videoç»„
sudo usermod -a -G video $USER
```

### Windows
```bash
# ä½¿ç”¨condaå®‰è£…éŸ³é¢‘ä¾èµ–ï¼ˆæ¨èï¼‰
conda install pyaudio

# æˆ–ä¸‹è½½é¢„ç¼–è¯‘åŒ…
# https://www.lfd.uci.edu/~gohlke/pythonlibs/#pyaudio

# å®‰è£…å…¶ä»–ä¾èµ–
pip install -r requirements_camera.txt
```

## ğŸ’¡ ä½¿ç”¨åœºæ™¯ç¤ºä¾‹

### 1. ç ”ç©¶å¼€å‘
```bash
# å¯åŠ¨ç›‘æµ‹ï¼Œä¿å­˜ç»“æœç”¨äºåˆ†æ
python realtime_camera_emotion.py \
    --model_path ./checkpoints/best_model.pth \
    --save_results
```

### 2. å®æ—¶åº”ç”¨é›†æˆ
```bash
# ä½¿ç”¨ONNXæ¨¡å‹æé«˜æ¨ç†é€Ÿåº¦
python realtime_camera_emotion.py \
    --model_path ./exported_models/model.onnx \
    --no_stats
```

### 3. æ€§èƒ½æµ‹è¯•
```bash
# ä½¿ç”¨é‡åŒ–æ¨¡å‹ï¼Œé™ä½èµ„æºæ¶ˆè€—
python realtime_camera_emotion.py \
    --model_path ./checkpoints/best_model.pth \
    --resolution 640x480
```

## ğŸ” æ•…éšœæ’é™¤

### é—®é¢˜1ï¼šæ‘„åƒå¤´æ— æ³•æ‰“å¼€

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# æ£€æŸ¥å¯ç”¨æ‘„åƒå¤´
python -c "import cv2; print([i for i in range(5) if cv2.VideoCapture(i).isOpened()])"

# å°è¯•ä¸åŒID
python realtime_camera_emotion.py --model_path ./checkpoints/best_model.pth --camera_id 1
```

### é—®é¢˜2ï¼šéŸ³é¢‘å½•åˆ¶å¤±è´¥

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# æ£€æŸ¥éŸ³é¢‘è®¾å¤‡
python -c "import pyaudio; p=pyaudio.PyAudio(); [print(f'{i}: {p.get_device_info_by_index(i)}') for i in range(p.get_device_count())]"

# macOSæƒé™è®¾ç½®
# ç³»ç»Ÿåå¥½è®¾ç½® -> å®‰å…¨æ€§ä¸éšç§ -> éšç§ -> éº¦å…‹é£ -> å…è®¸ç»ˆç«¯
```

### é—®é¢˜3ï¼šæ€§èƒ½ä¸è¶³

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# ä½¿ç”¨ç®€åŒ–ç‰ˆ
python simple_camera_emotion.py

# æˆ–å…³é—­ç»Ÿè®¡å›¾è¡¨
python realtime_camera_emotion.py --model_path ./checkpoints/best_model.pth --no_stats

# ä½¿ç”¨é‡åŒ–æ¨¡å‹
python realtime_camera_emotion.py --model_path ./exported_models/model_quantized.pth
```

### é—®é¢˜4ï¼šæ£€æµ‹ç²¾åº¦ä¸é«˜

**ä¼˜åŒ–å»ºè®®ï¼š**
- ç¡®ä¿å……è¶³å…‰ç…§
- ä¿æŒäººè„¸æ­£å¯¹æ‘„åƒå¤´
- è·ç¦»æ‘„åƒå¤´50-150cm
- é¿å…å¼ºçƒˆèƒŒå…‰
- ä½¿ç”¨é«˜è´¨é‡æ‘„åƒå¤´

## ğŸ“Š ç»“æœåˆ†æ

### å®æ—¶æ˜¾ç¤ºè¯´æ˜
- **äººè„¸æ¡†é¢œè‰²ï¼š** ä¸åŒé¢œè‰²ä»£è¡¨ä¸åŒæƒ…ç»ª
- **ç½®ä¿¡åº¦ï¼š** æ•°å€¼è¶Šé«˜è¡¨ç¤ºè¯†åˆ«è¶Šå‡†ç¡®
- **æ¦‚ç‡æ¡ï¼š** æ˜¾ç¤ºå„ç§æƒ…ç»ªçš„å¯èƒ½æ€§
- **ç»Ÿè®¡ä¿¡æ¯ï¼š** FPSã€æ£€æµ‹æ¬¡æ•°ã€ä¸»å¯¼æƒ…ç»ª

### ä¿å­˜çš„æ–‡ä»¶
```
emotion_session_20231201_143022.json    # å®Œæ•´ä¼šè¯è®°å½•
emotion_snapshot_20231201_143022.json   # å¿«ç…§è®°å½•
emotion_screenshot_20231201_143022.jpg  # æˆªå›¾æ–‡ä»¶
```

### æ•°æ®åˆ†æè„šæœ¬
```python
import json
import matplotlib.pyplot as plt
from collections import Counter

# åŠ è½½æ•°æ®
with open('emotion_session_20231201_143022.json', 'r') as f:
    data = json.load(f)

# æƒ…ç»ªåˆ†å¸ƒåˆ†æ
emotions = [r['emotion'] for r in data['detailed_results']]
print("æƒ…ç»ªåˆ†å¸ƒ:", Counter(emotions))

# å¹³å‡ç½®ä¿¡åº¦
confidences = [r['confidence'] for r in data['detailed_results']]
print(f"å¹³å‡ç½®ä¿¡åº¦: {sum(confidences)/len(confidences):.3f}")

# ä¸»å¯¼æƒ…ç»ª
dominant = Counter(emotions).most_common(1)[0]
print(f"ä¸»å¯¼æƒ…ç»ª: {dominant[0]} ({dominant[1]}æ¬¡)")
```

## ğŸ¨ è‡ªå®šä¹‰é…ç½®

### ä¿®æ”¹æƒ…ç»ªæ ‡ç­¾
```python
# åœ¨è„šæœ¬ä¸­ä¿®æ”¹
self.emotion_labels = [
    'ä¸­æ€§', 'å¼€å¿ƒ', 'æ‚²ä¼¤', 'æ„¤æ€’',
    'ææƒ§', 'åŒæ¶', 'æƒŠè®¶'
]
```

### è°ƒæ•´æ£€æµ‹å‚æ•°
```python
# äººè„¸æ£€æµ‹å‚æ•°
faces = self.face_cascade.detectMultiScale(
    gray, 
    scaleFactor=1.1,      # ç¼©æ”¾å› å­
    minNeighbors=5,       # æœ€å°é‚»å±…æ•°
    minSize=(50, 50)      # æœ€å°äººè„¸å°ºå¯¸
)
```

### ä¿®æ”¹é¢œè‰²ä¸»é¢˜
```python
# æƒ…ç»ªé¢œè‰²æ˜ å°„
self.emotion_colors = {
    'Happy': (0, 255, 0),      # ç»¿è‰²
    'Sad': (255, 0, 0),        # è“è‰²
    'Angry': (0, 0, 255),      # çº¢è‰²
    # ... è‡ªå®šä¹‰å…¶ä»–é¢œè‰²
}
```

## ğŸ“š è¿›é˜¶åŠŸèƒ½

### æ‰¹é‡å¤„ç†è§†é¢‘æ–‡ä»¶

### é›†æˆåˆ°Webåº”ç”¨

**Flaskç¤ºä¾‹ï¼š**
```python
# ä½¿ç”¨Flaskåˆ›å»ºWebæ¥å£
from flask import Flask, Response, jsonify
import cv2

app = Flask(__name__)
detector = EmotionDetector('./checkpoints/best_model.pth')

@app.route('/video_feed')
def video_feed():
    def generate():
        cap = cv2.VideoCapture(0)
        while True:
            ret, frame = cap.read()
            # ... æƒ…ç»ªæ£€æµ‹å’Œç»˜åˆ¶
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + 
                   cv2.imencode('.jpg', frame)[1].tobytes() + b'\r\n')
    
    return Response(generate(), mimetype='multipart/x-mixed-replace; boundary=frame')

if __name__ == '__main__':
    app.run(debug=True)
```

## ğŸ¤ è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·ï¼š

1. æŸ¥çœ‹ [README.md](README.md) ä¸­çš„è¯¦ç»†æ–‡æ¡£
2. æ£€æŸ¥ [å¸¸è§é—®é¢˜](README.md#å¸¸è§é—®é¢˜) éƒ¨åˆ†
3. æäº¤ Issue æè¿°å…·ä½“é—®é¢˜
4. å‚è€ƒç¤ºä¾‹ä»£ç å’Œé…ç½®æ–‡ä»¶

## ğŸ“ˆ æ€§èƒ½åŸºå‡†

### æµ‹è¯•ç¯å¢ƒ
- **CPU:** Intel i7-10700K
- **GPU:** RTX 3070
- **å†…å­˜:** 32GB DDR4
- **æ‘„åƒå¤´:** 1080p@30fps

### æ€§èƒ½æ•°æ®
| æ¨¡å¼ | FPS | CPUä½¿ç”¨ç‡ | å†…å­˜å ç”¨ | ç²¾åº¦ |
|------|-----|-----------|----------|------|
| ç®€åŒ–ç‰ˆ | 25-30 | 15-25% | 200MB | 65% |
| å®Œæ•´ç‰ˆ(CPU) | 8-12 | 60-80% | 1.5GB | 85% |
| å®Œæ•´ç‰ˆ(GPU) | 20-25 | 20-30% | 2GB | 85% |
| ONNXä¼˜åŒ– | 15-20 | 40-50% | 800MB | 83% |

---

**å¼€å§‹æ‚¨çš„æƒ…ç»ªç›‘æµ‹ä¹‹æ—…å§ï¼** ğŸ‰